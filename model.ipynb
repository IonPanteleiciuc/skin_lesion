{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import random as rd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data importation & visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"ISIC_2020_Training_GroundTruth_v2.csv\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/227x227/\"\n",
    "\n",
    "data_ids = os.listdir(data_dir)\n",
    "data_nb = len(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metadata[[\"image_name\", \"target\"]]\n",
    "X_paths = df[\"image_name\"].values\n",
    "\n",
    "label_0 = df.loc[df['target'] == 0]\n",
    "label_1 = df.loc[df['target'] == 1]\n",
    "\n",
    "nb_label_0 = label_0.shape[0]\n",
    "nb_label_1 = label_1.shape[0]\n",
    "total_labeled_data = nb_label_0 + nb_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total data: {data_nb}\")\n",
    "print(f\"Total labeled data: {total_labeled_data}\")\n",
    "print(f\"Total unlabeled data: {data_nb - total_labeled_data}\\n\")\n",
    "\n",
    "print(f\"We have {nb_label_0} ({np.round(nb_label_0/total_labeled_data * 100, 2) } %) benign labeled samples\")\n",
    "\n",
    "print(f\"We have {nb_label_1} ({np.round(nb_label_1/total_labeled_data * 100, 2)} %) malignant labeled samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeImages(dim):\n",
    "  if not os.path.exists(f\"data/{dim}x{dim}/\"):\n",
    "    os.makedirs(f\"data/{dim}x{dim}/\")\n",
    "  for idx, img_path in enumerate(os.listdir(data_dir)):\n",
    "    img = Image.open(data_dir + img_path)\n",
    "    new_img = img.resize((dim, dim))\n",
    "    new_img.save(f\"data/{dim}x{dim}/\" + img_path)\n",
    "    if idx % 100 == 0:\n",
    "      print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getY(image_name):\n",
    "  image_name = image_name.strip(\".jpg\")\n",
    "  img = df.loc[df['image_name'] == str(image_name)]\n",
    "  res = img[\"target\"]\n",
    "  return res.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_data = \"data/malignant/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(id):\n",
    "    return Image.open(data_dir + str(id) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img_id_label_1 = df.loc[df[\"target\"] == 1][\"image_name\"].values\n",
    "list_img_id_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getY(\"ISIC_0149568\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate malignant data\n",
    "for id in list_img_id_label_1:\n",
    "    os.popen(f'cp /Users/panteleiciuc/Desktop/ISEP/A3/ML_DL/skin_lesion/data/227x227/{id}.jpg /Users/panteleiciuc/Desktop/ISEP/A3/ML_DL/skin_lesion/data/malignant/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(img_id, zoom):\n",
    "    img_id = str(img_id).strip(\".jpg\")\n",
    "    img = Image.open(malignant_data + str(img_id) + \".jpg\")\n",
    "\n",
    "    alpha = zoom - 1\n",
    "\n",
    "    width, height = img.size\n",
    "\n",
    "    left = width * alpha\n",
    "    right = width * (1-alpha)\n",
    "\n",
    "    top = height * alpha\n",
    "    bottom = height * (1-alpha)\n",
    "\n",
    "    box = (left, top, right, bottom)\n",
    "\n",
    "    new_img = img.crop(box).resize((width, height), Image.LANCZOS)\n",
    "    new_img_name = f\"{img_id}_zoom_{zoom}.jpg\"\n",
    "\n",
    "    new_img.save(malignant_data + new_img_name)\n",
    "\n",
    "    return new_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img_id):\n",
    "    img_id = str(img_id).strip(\".jpg\")\n",
    "    img = Image.open(malignant_data + str(img_id) + \".jpg\")\n",
    "    \n",
    "    img_rot_90 = img.rotate(90)\n",
    "    img_rot_180 = img.rotate(180)\n",
    "    img_rot_270 = img.rotate(270)\n",
    "\n",
    "    new_name_90 = f\"{img_id}_r90.jpg\"\n",
    "    new_name_180 = f\"{img_id}_r180.jpg\"\n",
    "    new_name_270 = f\"{img_id}_r270.jpg\"\n",
    "\n",
    "    img_rot_90.save(malignant_data + new_name_90)\n",
    "    img_rot_180.save(malignant_data + new_name_180)\n",
    "    img_rot_270.save(malignant_data + new_name_270)\n",
    "\n",
    "\n",
    "    # return img_rot_90, img_rot_180, img_rot_270\n",
    "    return new_name_90, new_name_180, new_name_270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror(img_id):\n",
    "\n",
    "    img_id = str(img_id).strip(\".jpg\")\n",
    "    img = Image.open(malignant_data + str(img_id) + \".jpg\")\n",
    "\n",
    "    horizontal = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    new_name = f\"{img_id}_mh.jpg\"\n",
    "    horizontal.save(malignant_data + new_name)\n",
    "\n",
    "    # return horizontal\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNewImages(img_id):\n",
    "    m_img_id = mirror(img_id)\n",
    "\n",
    "    r90, r180, r270 = rotate(img_id)\n",
    "    m_r90, m_r180, m_r270 = rotate(m_img_id)\n",
    "\n",
    "    zoom(img_id, 1.1)\n",
    "    zoom(img_id, 1.2)\n",
    "\n",
    "    zoom(r90, 1.1)\n",
    "    zoom(r90, 1.2)\n",
    "\n",
    "    zoom(r180, 1.1)\n",
    "    zoom(r180, 1.2)\n",
    "\n",
    "    zoom(r270, 1.1)\n",
    "    zoom(r270, 1.2)\n",
    "    \n",
    "    zoom(m_img_id, 1.1)\n",
    "    zoom(m_img_id, 1.2)\n",
    "\n",
    "    zoom(m_r90, 1.1)\n",
    "    zoom(m_r90, 1.2)\n",
    "\n",
    "    zoom(m_r180, 1.1)\n",
    "    zoom(m_r180, 1.2)\n",
    "\n",
    "    zoom(m_r270, 1.1)\n",
    "    zoom(m_r270, 1.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multply malignant data\n",
    "# for idx, id in enumerate(list_img_id_label_1):\n",
    "#     generateNewImages(id)\n",
    "#     if idx % 50 == 0:\n",
    "#         print(idx)\n",
    "\n",
    "print(f\"# new imgaes in the malignant directory: {len(os.listdir(malignant_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete original malignant images\n",
    "# for id in list_img_id_label_1:\n",
    "#     os.popen(f'rm /Users/panteleiciuc/Desktop/ISEP/A3/ML_DL/skin_lesion/data/malignant/{id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_malignant_ids = os.listdir(malignant_data)\n",
    "new_malignant_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put back in data dir\n",
    "for idx, id in enumerate(new_malignant_ids):\n",
    "    \n",
    "    src = f\"/Users/panteleiciuc/Desktop/ISEP/A3/ML_DL/skin_lesion/data/malignant/{id}\"\n",
    "    dest = \"/Users/panteleiciuc/Desktop/ISEP/A3/ML_DL/skin_lesion/data/227x227/\"\n",
    "\n",
    "    os.popen(f'cp {src} {dest}') \n",
    "\n",
    "    if idx % 250 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'image_name': new_malignant_ids, 'target': [1] * len(new_malignant_ids)}\n",
    "\n",
    "\n",
    "df1 = df.copy()\n",
    "df2 = pd.DataFrame(data=d)\n",
    "\n",
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(len(df1) + len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNewData(df):\n",
    "    n = len(df)\n",
    "    for idx,id in enumerate(new_malignant_ids):\n",
    "        df.loc[n + idx] = [str(id).strip(\".jpg\"), 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the new images\n",
    "df = labelNewData(df.copy())\n",
    "df[\"arr\"] = \"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nb = len(os.listdir(data_dir))\n",
    "X_ids = df[\"image_name\"].values\n",
    "\n",
    "label_0 = df.loc[df['target'] == 0]\n",
    "label_1 = df.loc[df['target'] == 1]\n",
    "\n",
    "nb_label_0 = label_0.shape[0]\n",
    "nb_label_1 = label_1.shape[0]\n",
    "total_labeled_data = nb_label_0 + nb_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total data: {data_nb}\")\n",
    "print(f\"Total labeled data: {total_labeled_data}\")\n",
    "print(f\"Total unlabeled data: {data_nb - total_labeled_data}\\n\")\n",
    "\n",
    "print(f\"We have {nb_label_0} ({np.round(nb_label_0/total_labeled_data * 100, 2) } %) benign labeled samples\")\n",
    "\n",
    "print(f\"We have {nb_label_1} ({np.round(nb_label_1/total_labeled_data * 100, 2)} %) malignant labeled samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[:2]\n",
    "new_df = df_test.set_index(\"image_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JPGToArray(id):\n",
    "  id = id.strip(\".jpg\")\n",
    "  path = data_dir + id + \".jpg\"\n",
    "  jpg = Image.open(path)\n",
    "  img_arr = np.asarray(jpg)\n",
    "  return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArray():\n",
    "  for id in df.index:\n",
    "    df.loc[f\"{id}\", \"arr\"] = np.array([JPGToArray(id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_pickle('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>arr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ISIC_2637011</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[[192 142 141], [183 133 132], [154 104 107]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISIC_0015719</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[[158  98  70], [156  96  68], [158  98  74]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target                                                arr\n",
       "image_name                                                             \n",
       "ISIC_2637011       0  [[[[192 142 141], [183 133 132], [154 104 107]...\n",
       "ISIC_0015719       0  [[[[158  98  70], [156  96  68], [158  98  74]..."
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df = pd.read_pickle('hello')\n",
    "loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(train_percentage, validation_percentage, test_percentage):\n",
    "\n",
    "  if train_percentage + validation_percentage + test_percentage != 1:\n",
    "    return False\n",
    "\n",
    "  img_paths = os.listdir(data_dir)[:] # limit the db\n",
    "\n",
    "  total_data_len = len(img_paths)\n",
    "\n",
    "  train_len = np.round(total_data_len * train_percentage).astype(\"int\")\n",
    "  validation_len = np.round(total_data_len * validation_percentage).astype(\"int\")\n",
    "  test_len = np.round(total_data_len * test_percentage).astype(\"int\")\n",
    "\n",
    "  rd.shuffle(img_paths)\n",
    "\n",
    "  train_paths = img_paths[:train_len]\n",
    "  validation_paths = img_paths[train_len:train_len+validation_len]\n",
    "  test_paths = img_paths[train_len+validation_len:]\n",
    "\n",
    "  return train_paths, validation_paths, test_paths\n",
    "\n",
    "# tr_p, val_p, test_p = splitData(0.8, 0.1, 0.1)\n",
    "train_paths, validation_paths, test_paths = splitData(0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(paths):\n",
    "  labels = []\n",
    "  for im_path in paths:\n",
    "    labels.append(getY(im_path))\n",
    "  return np.resize(np.array(labels), (len(labels), 1))\n",
    "\n",
    "# print(getLabels(val_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathsToArray(paths):\n",
    "  data_arr = []\n",
    "  for idx,img_path in enumerate(paths):\n",
    "    path = data_dir + img_path\n",
    "    im_arr = np.array(Image.open(path))\n",
    "    data_arr.append(im_arr)\n",
    "    print(idx)\n",
    "  return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_paths)\n",
    "pathsToArray(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('train_ar.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigPathToArray(paths):\n",
    "  arr = []\n",
    "  step = 2640\n",
    "  for i in range(10):\n",
    "    print(\"From: \", i*step)\n",
    "    print(\"To: \", (i+1)*step)\n",
    "    interm_path = paths[i*step:(i+1)*step]\n",
    "\n",
    "    for img_path in interm_path:\n",
    "      path = data_dir + img_path\n",
    "      im_arr = np.array(Image.open(path))\n",
    "      # arr = arr + im_arr\n",
    "      arr.append(im_arr)\n",
    "\n",
    "  return arr\n",
    "\n",
    "\n",
    "# train_images = bigPathToArray(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_portion, val_portion, test_portion):\n",
    "  train_paths, validation_paths, test_paths = splitData(train_portion, val_portion, test_portion)\n",
    "  \n",
    "  train_images = pathsToArray(train_paths)\n",
    "  train_labels = getLabels(train_paths)\n",
    "\n",
    "  validation_images = pathsToArray(validation_paths)\n",
    "  validation_labels = getLabels(validation_paths)\n",
    "\n",
    "  test_images = pathsToArray(test_paths)\n",
    "  test_labels = getLabels(test_paths)\n",
    "\n",
    "  return (train_images, train_labels), (validation_images, validation_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pathsToArray(train_paths)\n",
    "train_labels = getLabels(train_paths)\n",
    "\n",
    "validation_images = pathsToArray(validation_paths)\n",
    "validation_labels = getLabels(validation_paths)\n",
    "\n",
    "test_images = pathsToArray(test_paths)\n",
    "test_labels = getLabels(test_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AlexNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "(train_images, train_labels), (validation_images, validation_labels), (test_images, test_labels) = load_data(0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images))\n",
    "print(len(train_images[0]))\n",
    "print(len(train_images[0][0]))\n",
    "print(len(train_images[0][0][0]))\n",
    "# print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES= [\"benign\", \"malignant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, (image, label) in enumerate(train_ds.take(5)):\n",
    "    ax = plt.subplot(5,5,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(CLASS_NAMES[label.numpy()[0]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
    "validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
    "\n",
    "print(\"Training data size:\", train_ds_size)\n",
    "print(\"Test data size:\", test_ds_size)\n",
    "print(\"Validation data size:\", validation_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "test_ds = (test_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "                  \n",
    "validation_ds = (validation_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds,\n",
    "          epochs=20,\n",
    "          validation_data=validation_ds,\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./checkpoints/My_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model/my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
